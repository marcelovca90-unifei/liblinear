name	method	nf	hamPrecision	spamPrecision	avgPrecision	hamRecall	spamRecall	avgRecall	areaUnderPRC	areaUnderROC	hamFMeasure	spamFMeasure	fMeasure	trainTime	testTime
LING_SPAM	FD	1024	98,15 ± 0,29	98,26 ± 0,10	98,21 ± 0,15	98,10 ± 0,11	98,31 ± 0,26	98,20 ± 0,14	49,97 ± 0,14	98,20 ± 0,14	98,12 ± 0,16	98,12 ± 0,16	98,20 ± 0,15	00:00:03.972 ± 00:00:00.374	00:00:00.551 ± 00:00:00.017
SPAM_ASSASSIN	MI	128	93,51 ± 0,53	97,03 ± 0,40	95,27 ± 0,20	96,90 ± 0,41	93,79 ± 0,49	95,35 ± 0,20	51,62 ± 0,40	95,35 ± 0,20	95,17 ± 0,21	95,17 ± 0,21	95,31 ± 0,20	00:00:01.111 ± 00:00:00.102	00:00:00.284 ± 00:00:00.003
SPAM_ASSASSIN	MI	256	93,91 ± 0,51	96,99 ± 0,32	95,45 ± 0,27	96,83 ± 0,32	94,19 ± 0,54	95,51 ± 0,28	51,40 ± 0,33	95,51 ± 0,28	95,35 ± 0,26	95,35 ± 0,26	95,48 ± 0,27	00:00:02.216 ± 00:00:00.095	00:00:00.317 ± 00:00:00.003
TREC	MI	1024	81,55 ± 0,15	92,58 ± 0,17	87,07 ± 0,11	93,36 ± 0,15	79,69 ± 0,19	86,53 ± 0,11	56,44 ± 0,13	86,53 ± 0,11	87,06 ± 0,10	87,06 ± 0,10	86,80 ± 0,11	00:09:36.610 ± 00:01:07.742	00:00:08.907 ± 00:00:00.030
UNIFEI_CRUDE	MI	1024	79,30 ± 0,07	87,14 ± 0,16	83,22 ± 0,10	88,61 ± 0,16	76,95 ± 0,07	82,78 ± 0,09	55,10 ± 0,08	82,78 ± 0,09	83,70 ± 0,09	83,70 ± 0,09	83,00 ± 0,09	01:41:19.630 ± 00:31:09.759	00:00:38.344 ± 00:00:01.089
UNIFEI_DELTA_0	MI	1024	78,35 ± 0,21	86,54 ± 0,17	82,45 ± 0,17	87,83 ± 0,16	76,34 ± 0,27	82,08 ± 0,17	55,10 ± 0,13	82,08 ± 0,17	82,82 ± 0,16	82,82 ± 0,16	82,27 ± 0,17	01:06:31.932 ± 00:14:08.505	00:00:23.122 ± 00:00:01.792
