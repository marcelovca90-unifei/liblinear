name	method	nf	hamPrecision	spamPrecision	avgPrecision	hamRecall	spamRecall	avgRecall	areaUnderPRC	areaUnderROC	hamFMeasure	spamFMeasure	fMeasure	trainTime	testTime
LING_SPAM	FD	1024	98,13 ± 0,19	98,23 ± 0,10	98,18 ± 0,08	98,07 ± 0,10	98,29 ± 0,17	98,18 ± 0,08	49,97 ± 0,12	98,18 ± 0,08	98,10 ± 0,09	98,10 ± 0,09	98,18 ± 0,08	00:00:01.817 ± 00:00:00.191	00:00:00.315 ± 00:00:00.034
SPAM_ASSASSIN	MI	128	93,25 ± 0,53	96,82 ± 0,56	95,04 ± 0,24	96,67 ± 0,58	93,55 ± 0,50	95,11 ± 0,25	51,63 ± 0,47	95,11 ± 0,25	94,93 ± 0,24	94,93 ± 0,24	95,07 ± 0,24	00:00:00.568 ± 00:00:00.011	00:00:00.212 ± 00:00:00.002
SPAM_ASSASSIN	MI	256	95,11 ± 0,50	94,18 ± 0,89	94,65 ± 0,33	93,61 ± 1,00	95,56 ± 0,47	94,58 ± 0,38	49,31 ± 0,63	94,58 ± 0,38	94,34 ± 0,38	94,34 ± 0,38	94,62 ± 0,35	00:00:00.603 ± 00:00:00.036	00:00:00.232 ± 00:00:00.016
TREC	MI	1024	85,42 ± 1,83	81,33 ± 6,42	83,37 ± 2,30	77,40 ± 9,77	86,81 ± 3,49	82,10 ± 3,14	47,26 ± 4,96	82,10 ± 3,14	80,43 ± 4,59	80,43 ± 4,59	82,73 ± 2,72	00:01:35.647 ± 00:00:01.137	00:00:01.968 ± 00:00:00.014
UNIFEI_CRUDE	MI	1024	84,23 ± 1,65	78,08 ± 2,14	81,16 ± 0,26	75,57 ± 3,64	85,68 ± 2,50	80,63 ± 0,58	46,20 ± 2,32	80,63 ± 0,58	79,51 ± 1,24	79,51 ± 1,24	80,89 ± 0,42	00:07:48.190 ± 00:00:03.184	00:00:07.738 ± 00:00:00.132
UNIFEI_DELTA_0	MI	1024	83,07 ± 2,24	79,93 ± 2,41	81,50 ± 0,11	77,93 ± 4,23	84,16 ± 3,21	81,05 ± 0,51	47,88 ± 2,81	81,05 ± 0,51	80,18 ± 1,28	80,18 ± 1,28	81,27 ± 0,31	00:05:58.285 ± 00:00:07.515	00:00:05.604 ± 00:00:00.190
