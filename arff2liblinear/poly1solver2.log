name	method	nf	hamPrecision	spamPrecision	avgPrecision	hamRecall	spamRecall	avgRecall	areaUnderPRC	areaUnderROC	hamFMeasure	spamFMeasure	fMeasure	trainTime	testTime
LING_SPAM	FD	1024	97,23 ± 0,74	97,97 ± 0,22	97,60 ± 0,47	97,79 ± 0,23	97,44 ± 0,69	97,62 ± 0,45	50,26 ± 0,25	97,62 ± 0,45	97,50 ± 0,48	97,50 ± 0,48	97,61 ± 0,46	00:00:00.381 ± 00:00:00.022	00:00:00.292 ± 00:00:00.017
SPAM_ASSASSIN	MI	128	93,23 ± 0,45	96,77 ± 0,52	95,00 ± 0,27	96,62 ± 0,53	93,53 ± 0,42	95,07 ± 0,28	51,62 ± 0,38	95,07 ± 0,28	94,89 ± 0,27	94,89 ± 0,27	95,04 ± 0,28	00:00:00.263 ± 00:00:00.016	00:00:00.248 ± 00:00:00.015
SPAM_ASSASSIN	MI	256	95,01 ± 0,47	94,20 ± 0,88	94,61 ± 0,34	93,63 ± 0,98	95,46 ± 0,45	94,55 ± 0,38	49,37 ± 0,61	94,55 ± 0,38	94,31 ± 0,39	94,31 ± 0,39	94,58 ± 0,36	00:00:00.295 ± 00:00:00.002	00:00:00.263 ± 00:00:00.005
TREC	MI	1024	85,41 ± 1,33	81,12 ± 4,68	83,27 ± 1,68	77,11 ± 7,15	86,84 ± 2,54	81,98 ± 2,31	47,14 ± 3,61	81,98 ± 2,31	80,27 ± 3,38	80,27 ± 3,38	82,61 ± 2,00	00:00:05.224 ± 00:00:00.484	00:00:01.916 ± 00:00:00.013
UNIFEI_CRUDE	MI	1024	84,30 ± 1,64	78,06 ± 2,12	81,18 ± 0,25	75,53 ± 3,62	85,77 ± 2,48	80,65 ± 0,57	46,15 ± 2,30	80,65 ± 0,57	79,51 ± 1,24	79,51 ± 1,24	80,91 ± 0,41	00:00:25.850 ± 00:00:02.010	00:00:07.275 ± 00:00:00.064
UNIFEI_DELTA_0	MI	1024	83,02 ± 2,26	79,90 ± 2,41	81,46 ± 0,10	77,90 ± 4,24	84,11 ± 3,24	81,00 ± 0,50	47,90 ± 2,82	81,00 ± 0,50	80,14 ± 1,28	80,14 ± 1,28	81,23 ± 0,30	00:00:15.199 ± 00:00:01.050	00:00:05.460 ± 00:00:00.031
